{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPK8BbO3azURq/TlC1FWVPP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8urZn3sj8Dm","executionInfo":{"status":"ok","timestamp":1695794523928,"user_tz":-420,"elapsed":15,"user":{"displayName":"Денис Анциферов","userId":"17211201011086993294"}},"outputId":"4ef6c158-9b76-44ba-8b1b-515d497094b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep 27 06:02:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["%%writefile relu.cu\n","#include <torch/extension.h>\n","\n","\n","__global__ void d_relu(float *a, float *res, int n) {\n","    int i = blockDim.x * blockIdx.x + threadIdx.x;\n","\n","    if (i < n) {\n","        if (*(a+i) > 0.0) {\n","            *(res+i) = *(a+i);\n","        }\n","        else {\n","            *(res+i) = 0;\n","        }\n","    }\n","}\n","\n","\n","#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n","#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n","#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","\n","const int block_size = 128;\n","\n","\n","__forceinline__ int calc_grid_size(int m) {\n","    return (m + block_size - 1) / block_size;\n","}\n","\n","\n","torch::Tensor relu(torch::Tensor a) {\n","    CHECK_INPUT(a);\n","\n","    auto res = torch::empty_like(a);\n","    int n = a.numel();\n","\n","    d_relu<<<calc_grid_size(n), block_size>>>(\n","        a.data_ptr<float>(),\n","        res.data_ptr<float>(),\n","        n\n","    );\n","\n","    return res;\n","}\n","\n","\n","PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n","    m.def(\"my_relu\", &relu, \"Custom vector ReLU-function\");\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSnpiiBsj-_2","executionInfo":{"status":"ok","timestamp":1695794523928,"user_tz":-420,"elapsed":11,"user":{"displayName":"Денис Анциферов","userId":"17211201011086993294"}},"outputId":"9c57ecbb-7785-47d7-892c-67a41766b2fb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting relu.cu\n"]}]},{"cell_type":"code","source":["%%writefile main.py\n","import unittest\n","import torch\n","import numpy as np\n","from torch.utils.cpp_extension import load\n","\n","\n","class LabTest(unittest.TestCase):\n","    @classmethod\n","    def setUpClass(cls):\n","        cls.ext = load(\n","            name='my_extension',\n","            sources=['relu.cu'],\n","            extra_cuda_cflags=['-O2'],\n","            extra_cflags=['-O2'],\n","        )\n","\n","    def test_relu(self):\n","        n = torch.randint(size=(1,), low=1, high=2048)\n","\n","        x = torch.rand((n,), device='cuda')\n","        z = LabTest.ext.my_relu(x)\n","\n","        # z_ = x * (x > 0).float()\n","        z_ = torch.nn.functional.relu(x)\n","\n","        self.assertTrue(torch.allclose(z, z_, atol=1e-7, rtol=1e-6))\n","\n","\n","if __name__ == '__main__':\n","    unittest.main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbru7xYQkKhr","executionInfo":{"status":"ok","timestamp":1695794523929,"user_tz":-420,"elapsed":9,"user":{"displayName":"Денис Анциферов","userId":"17211201011086993294"}},"outputId":"9e2e1dd0-807e-4deb-a8a9-dfcb6d6a400f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting main.py\n"]}]},{"cell_type":"code","source":["%pip install Ninja\n","%run main.py\n","%tb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVWXOISQkTZb","executionInfo":{"status":"ok","timestamp":1695794607886,"user_tz":-420,"elapsed":83965,"user":{"displayName":"Денис Анциферов","userId":"17211201011086993294"}},"outputId":"d2777db7-6525-41fa-f1bd-a310f1bd08f5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Ninja in /usr/local/lib/python3.10/dist-packages (1.11.1)\n"]},{"output_type":"stream","name":"stderr","text":[".\n","----------------------------------------------------------------------\n","Ran 1 test in 76.978s\n","\n","OK\n","No traceback available to show.\n"]}]}]}